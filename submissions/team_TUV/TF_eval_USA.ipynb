{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f80d183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(5415, 5) (5415, 1)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>Stage_m</th>\n",
       "      <th>ET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-03-01</th>\n",
       "      <td>0.000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>0.923499</td>\n",
       "      <td>1.380044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-03-02</th>\n",
       "      <td>0.000</td>\n",
       "      <td>7.222222</td>\n",
       "      <td>-8.333333</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>1.447215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-03-03</th>\n",
       "      <td>28.956</td>\n",
       "      <td>15.555556</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>1.161231</td>\n",
       "      <td>2.115481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-03-04</th>\n",
       "      <td>0.254</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>-7.777778</td>\n",
       "      <td>1.203901</td>\n",
       "      <td>1.031090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-03-05</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>1.085035</td>\n",
       "      <td>0.893230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.563036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>-3.888889</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.665206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-24</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>-1.111111</td>\n",
       "      <td>0.862542</td>\n",
       "      <td>0.602258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>9.906</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.981408</td>\n",
       "      <td>0.544738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-26</th>\n",
       "      <td>0.000</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.741567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5415 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PRCP       TMAX       TMIN   Stage_m        ET\n",
       "2002-03-01   0.000   6.666667 -11.111111  0.923499  1.380044\n",
       "2002-03-02   0.000   7.222222  -8.333333  0.911308  1.447215\n",
       "2002-03-03  28.956  15.555556   2.222222  1.161231  2.115481\n",
       "2002-03-04   0.254   2.222222  -7.777778  1.203901  1.031090\n",
       "2002-03-05   0.000   0.000000 -11.111111  1.085035  0.893230\n",
       "...            ...        ...        ...       ...       ...\n",
       "2016-12-22   0.000   2.222222 -11.111111  0.819872  0.563036\n",
       "2016-12-23   0.000   5.555556  -3.888889  0.819872  0.665206\n",
       "2016-12-24   0.000   5.555556  -1.111111  0.862542  0.602258\n",
       "2016-12-25   9.906   5.555556   0.555556  0.981408  0.544738\n",
       "2016-12-26   0.000   6.111111 -10.000000  0.911308  0.741567\n",
       "\n",
       "[5415 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import keras_tuner as kt\n",
    "\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from numpy import empty\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from os import chdir\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "import math\n",
    "\n",
    "csv_file_path = 'D:/Arbeit PhD/Fachlich/z_Sonstiges/Groundwater challenge/data/USA'\n",
    "chdir(csv_file_path)\n",
    "\n",
    "Y_all = pd.read_csv('heads.csv',decimal='.',index_col=0, delimiter=',', header=0,parse_dates=True)\n",
    "X_all = pd.read_csv('input_data.csv',decimal='.', delimiter=',',index_col=0, header=0,parse_dates=True)\n",
    "Y_temp = Y_all['2002-03-01':' 2016-12-26']\n",
    "X = X_all['2002-03-01':' 2016-12-26']\n",
    "print()\n",
    "\n",
    "# interpolate\n",
    "Y = Y_temp.reindex(pd.date_range(start=Y_temp.index.min(),end=Y_temp.index.max(),freq='1D')) \n",
    "Y.interpolate(method='linear', inplace=True)  \n",
    "print(X.shape, Y.shape)\n",
    "print(Y.isna().sum().sum())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fcce1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1091, 5)\n",
      "(1091, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:'2011-12-31']\n",
    "X_test = X['2014-01-01':]\n",
    "X_valid = X['2012-01-01':'2013-12-31']\n",
    "\n",
    "Y_train = Y[:'2011-12-31']\n",
    "Y_test = Y['2014-01-01':]\n",
    "Y_valid = Y['2012-01-01':'2013-12-31']\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "csv_file_path = 'D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge\\data'\n",
    "chdir(csv_file_path)\n",
    "from helper import *\n",
    "\n",
    "(dataset_train,dataset_test,dataset_valid,scaler_X,scaler_Y)=prepare_data(X_train,Y_train,X_valid,Y_valid,X_test,Y_test)\n",
    "\n",
    "x_final_unsplit = scaler_X.transform(X)\n",
    "y_final_unsplit = scaler_Y.transform(Y)\n",
    "dataset_train = np.concatenate((x_final_unsplit,y_final_unsplit), axis=1)\n",
    " \n",
    "iters=3\n",
    "n_steps_in=30\n",
    "n_steps_out=1\n",
    "\n",
    "x_final, y_final = split_sequences_y1(dataset_train, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65fc2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "class Dropout(keras.layers.Dropout):\n",
    "    def __init__(self, rate, training=None, noise_shape=None, seed=None, **kwargs):\n",
    "        super(Dropout, self).__init__(rate, noise_shape=None, seed=None,**kwargs)\n",
    "        self.training = training\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "\n",
    "            def dropped_inputs():\n",
    "                return K.dropout(inputs, self.rate, noise_shape,\n",
    "                                 seed=self.seed)\n",
    "            if not training: \n",
    "                return K.in_train_phase(dropped_inputs, inputs, training=self.training)\n",
    "            return K.in_train_phase(dropped_inputs, inputs, training=training)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ebe1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 30, 5)        10          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 30, 5)        1454        layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30, 5)        0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 30, 5)        0           dropout[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 30, 5)        10          tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 30, 2)        12          layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 2)        0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 30, 5)        15          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 30, 5)        0           conv1d_1[0][0]                   \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 30, 5)        10          tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 30, 5)        1454        layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 30, 5)        0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 30, 5)        0           dropout_2[0][0]                  \n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 30, 5)        10          tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 30, 2)        12          layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 2)        0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 30, 5)        15          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 30, 5)        0           conv1d_3[0][0]                   \n",
      "                                                                 tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 30)           0           tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 142)          4402        global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 142)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            143         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,547\n",
      "Trainable params: 7,547\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_runs = 100\n",
    "\n",
    "class MonteCarloLSTM(tf.keras.layers.LSTM):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "    \n",
    "#load models \n",
    "csv_file_path = 'D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge'\n",
    "chdir(csv_file_path)\n",
    "\n",
    "transformer_model = keras.models.load_model('TF_USA_tune.h5')\n",
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3bf0a",
   "metadata": {},
   "source": [
    "## Prediction Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b33ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5386, 30, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_final.shape)\n",
    "Y_pred_test_tr = np.empty((x_final.shape[0],n_steps_out,test_runs))\n",
    "y_correct_utf = scaler_Y.inverse_transform(y_final)#test\n",
    "for j in range(test_runs): \n",
    "    Y_pred_test_tr[:,:,j]=transformer_model.predict(x_final)\n",
    "    yhat_utf = scaler_Y.inverse_transform(Y_pred_test_tr[:,:,j])#test\n",
    "    #print(j)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "115e1413",
   "metadata": {},
   "source": [
    "## POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c54998ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5386, 1)\n",
      "0.9961010025993317\n"
     ]
    }
   ],
   "source": [
    "Y_pred = np.mean(Y_pred_test_tr, axis=2)\n",
    "Y_std = np.std(Y_pred_test_tr, axis=2)\n",
    "\n",
    "zT = 5\n",
    "T_ival = [Y_pred - zT*Y_std,Y_pred + zT*Y_std]\n",
    "#print(range(len(Y_test_day1)))\n",
    "def calc_POC(list_of_bounds, measured):\n",
    "    temp = 0 \n",
    "    for i in range(len(measured)):\n",
    "        if measured[i]< list_of_bounds[1][i] and measured[i]> list_of_bounds[0][i]:\n",
    "            temp = temp + 1\n",
    "    POC = temp/len(measured)\n",
    "    return POC\n",
    "\n",
    "print(T_ival[1].shape)\n",
    "POC_tr = calc_POC(T_ival,y_final)\n",
    "print(POC_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b38e0342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5386, 1, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[153.84882399],\n",
       "       [153.70788301],\n",
       "       [153.73007007],\n",
       "       ...,\n",
       "       [151.35421565],\n",
       "       [151.44139385],\n",
       "       [151.63149344]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_pred_test_tr.shape)\n",
    "Y_pred_test_tr_flat = Y_pred_test_tr.reshape((test_runs*Y_pred_test_tr.shape[0], 1))\n",
    "Y_pred_test_utf_flat = scaler_Y.inverse_transform(Y_pred_test_tr_flat)\n",
    "Y_pred_test_utf = Y_pred_test_utf_flat.reshape((Y_pred_test_tr.shape[0], 1,test_runs))\n",
    "Y_pred_calib = np.mean(Y_pred_test_utf, axis=2)\n",
    "Y_std_calib = np.std(Y_pred_test_utf, axis=2)\n",
    "T_ival_calib = [Y_pred_calib - zT*Y_std_calib,Y_pred_calib + zT*Y_std_calib]\n",
    "T_ival_calib[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "471b9bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>Stage_m</th>\n",
       "      <th>ET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>1.778</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>-9.444444</td>\n",
       "      <td>0.950930</td>\n",
       "      <td>0.675063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-7.222222</td>\n",
       "      <td>0.923499</td>\n",
       "      <td>0.694637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>1.270</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-6.666667</td>\n",
       "      <td>0.947882</td>\n",
       "      <td>0.527591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>17.526</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>1.161231</td>\n",
       "      <td>0.359905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>0.000</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>-5.555556</td>\n",
       "      <td>1.103322</td>\n",
       "      <td>0.836176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27</th>\n",
       "      <td>0.000</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>0.914355</td>\n",
       "      <td>4.372622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-28</th>\n",
       "      <td>17.526</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>15.555556</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>4.659461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-29</th>\n",
       "      <td>12.192</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>1.222188</td>\n",
       "      <td>4.665706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-30</th>\n",
       "      <td>0.000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9.444444</td>\n",
       "      <td>1.091131</td>\n",
       "      <td>5.309803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>0.254</td>\n",
       "      <td>28.888889</td>\n",
       "      <td>12.777778</td>\n",
       "      <td>1.005791</td>\n",
       "      <td>5.992429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1977 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PRCP       TMAX       TMIN   Stage_m        ET\n",
       "2017-01-01   1.778   4.444444  -9.444444  0.950930  0.675063\n",
       "2017-01-02   0.000   5.000000  -7.222222  0.923499  0.694637\n",
       "2017-01-03   1.270   1.666667  -6.666667  0.947882  0.527591\n",
       "2017-01-04  17.526   3.333333   1.111111  1.161231  0.359905\n",
       "2017-01-05   0.000   7.777778  -5.555556  1.103322  0.836176\n",
       "...            ...        ...        ...       ...       ...\n",
       "2022-05-27   0.000  21.111111   8.888889  0.914355  4.372622\n",
       "2022-05-28  17.526  25.555556  15.555556  0.978360  4.659461\n",
       "2022-05-29  12.192  22.222222   8.888889  1.222188  4.665706\n",
       "2022-05-30   0.000  25.000000   9.444444  1.091131  5.309803\n",
       "2022-05-31   0.254  28.888889  12.777778  1.005791  5.992429\n",
       "\n",
       "[1977 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path = 'D:/Arbeit PhD/Fachlich/z_Sonstiges/Groundwater challenge/data/USA'\n",
    "chdir(csv_file_path)\n",
    "\n",
    "X_all = pd.read_csv('input_data.csv',decimal='.',index_col=0, delimiter=',', header=0,parse_dates=True)\n",
    "\n",
    "X_finaltest = X_all['2017-01-01':]\n",
    "X_finaltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "857ef5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1948, 30, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_finaltest_trf = scaler_X.transform(X_finaltest)\n",
    "X_ftest = split_sequences_test(X_finaltest_trf,n_steps_in, n_steps_out)\n",
    "X_ftest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd03cb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5386, 30, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_final.shape)\n",
    "Y_pred_ftest_tr = np.empty((X_ftest.shape[0],n_steps_out,test_runs))\n",
    "for j in range(test_runs): \n",
    "    Y_pred_ftest_tr[:,:,j]=transformer_model.predict(X_ftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "992f5c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1948, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_ftest_tr_flat = Y_pred_ftest_tr.reshape((100*Y_pred_ftest_tr.shape[0], 1))\n",
    "Y_pred_ftest_utf_flat = scaler_Y.inverse_transform(Y_pred_ftest_tr_flat)\n",
    "Y_pred_ftest_utf = Y_pred_ftest_utf_flat.reshape((Y_pred_ftest_tr.shape[0], 1,100))\n",
    "yhat_mean = np.mean(Y_pred_ftest_utf, axis=2)\n",
    "yhat_std = np.std(Y_pred_ftest_utf, axis=2)\n",
    "T_ival_utf = [yhat_mean - zT*yhat_std,yhat_mean + zT*yhat_std]\n",
    "yhat_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0131cdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1948, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_idx_calib = pd.date_range(start='2002-03-30', end='2016-12-26')# 2002-03-01 to 2016-12-31\n",
    "final_idx_test = pd.date_range(start='2017-01-30', end='2022-05-31')#2017-01-01 to 2022-05-31\n",
    "final_df_calib = pd.DataFrame(index=final_idx_calib)\n",
    "final_df_test = pd.DataFrame(index=final_idx_test)\n",
    "final_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd94591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5386, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head forecast</th>\n",
       "      <th>95% lower</th>\n",
       "      <th>95% upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-03-30</th>\n",
       "      <td>152.599119</td>\n",
       "      <td>151.349413</td>\n",
       "      <td>153.848824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-03-31</th>\n",
       "      <td>152.586810</td>\n",
       "      <td>151.465738</td>\n",
       "      <td>153.707883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-01</th>\n",
       "      <td>152.661618</td>\n",
       "      <td>151.593165</td>\n",
       "      <td>153.730070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-02</th>\n",
       "      <td>152.659798</td>\n",
       "      <td>151.417166</td>\n",
       "      <td>153.902430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-03</th>\n",
       "      <td>152.750312</td>\n",
       "      <td>151.566397</td>\n",
       "      <td>153.934228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>149.943222</td>\n",
       "      <td>148.648636</td>\n",
       "      <td>151.237809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>149.957712</td>\n",
       "      <td>148.567568</td>\n",
       "      <td>151.347855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-24</th>\n",
       "      <td>150.004606</td>\n",
       "      <td>148.654996</td>\n",
       "      <td>151.354216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>149.975343</td>\n",
       "      <td>148.509292</td>\n",
       "      <td>151.441394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-26</th>\n",
       "      <td>150.090178</td>\n",
       "      <td>148.548862</td>\n",
       "      <td>151.631493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5386 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            head forecast   95% lower   95% upper\n",
       "2002-03-30     152.599119  151.349413  153.848824\n",
       "2002-03-31     152.586810  151.465738  153.707883\n",
       "2002-04-01     152.661618  151.593165  153.730070\n",
       "2002-04-02     152.659798  151.417166  153.902430\n",
       "2002-04-03     152.750312  151.566397  153.934228\n",
       "...                   ...         ...         ...\n",
       "2016-12-22     149.943222  148.648636  151.237809\n",
       "2016-12-23     149.957712  148.567568  151.347855\n",
       "2016-12-24     150.004606  148.654996  151.354216\n",
       "2016-12-25     149.975343  148.509292  151.441394\n",
       "2016-12-26     150.090178  148.548862  151.631493\n",
       "\n",
       "[5386 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_pred.shape)\n",
    "final_df_calib['head forecast'] = Y_pred_calib\n",
    "final_df_calib['95% lower'] = T_ival_calib[0]\n",
    "final_df_calib['95% upper'] = T_ival_calib[1]\n",
    "final_df_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bf8f98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head forecast</th>\n",
       "      <th>95% lower</th>\n",
       "      <th>95% upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-30</th>\n",
       "      <td>152.168012</td>\n",
       "      <td>151.121386</td>\n",
       "      <td>153.214638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-31</th>\n",
       "      <td>152.104987</td>\n",
       "      <td>151.001279</td>\n",
       "      <td>153.208695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>152.029914</td>\n",
       "      <td>151.135706</td>\n",
       "      <td>152.924122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-02</th>\n",
       "      <td>152.091838</td>\n",
       "      <td>151.128365</td>\n",
       "      <td>153.055312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-03</th>\n",
       "      <td>152.161370</td>\n",
       "      <td>151.191194</td>\n",
       "      <td>153.131546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27</th>\n",
       "      <td>152.351945</td>\n",
       "      <td>151.433442</td>\n",
       "      <td>153.270448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-28</th>\n",
       "      <td>152.337127</td>\n",
       "      <td>151.505844</td>\n",
       "      <td>153.168410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-29</th>\n",
       "      <td>152.281888</td>\n",
       "      <td>151.336601</td>\n",
       "      <td>153.227175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-30</th>\n",
       "      <td>152.268237</td>\n",
       "      <td>151.352588</td>\n",
       "      <td>153.183885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>152.247959</td>\n",
       "      <td>151.311285</td>\n",
       "      <td>153.184633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1948 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            head forecast   95% lower   95% upper\n",
       "2017-01-30     152.168012  151.121386  153.214638\n",
       "2017-01-31     152.104987  151.001279  153.208695\n",
       "2017-02-01     152.029914  151.135706  152.924122\n",
       "2017-02-02     152.091838  151.128365  153.055312\n",
       "2017-02-03     152.161370  151.191194  153.131546\n",
       "...                   ...         ...         ...\n",
       "2022-05-27     152.351945  151.433442  153.270448\n",
       "2022-05-28     152.337127  151.505844  153.168410\n",
       "2022-05-29     152.281888  151.336601  153.227175\n",
       "2022-05-30     152.268237  151.352588  153.183885\n",
       "2022-05-31     152.247959  151.311285  153.184633\n",
       "\n",
       "[1948 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_test['head forecast'] = yhat_mean\n",
    "final_df_test['95% lower'] = T_ival_utf[0]\n",
    "final_df_test['95% upper'] = T_ival_utf[1]\n",
    "final_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84672a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'D:/Arbeit PhD/Fachlich/z_Sonstiges/Groundwater challenge/submissions'\n",
    "chdir(csv_file_path)\n",
    "final_df_calib.to_csv('USA_calib.csv', float_format='%.2f')\n",
    "final_df_test.to_csv('USA_test.csv', float_format='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde11836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7593de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c383e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943825aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8362c94acb70529fb597ced4e020ad9ec7f0e835666f207c4442104931f7034b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
